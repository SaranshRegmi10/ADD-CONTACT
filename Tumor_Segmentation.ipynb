{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SaranshRegmi10/ADD-CONTACT/blob/main/Tumor_Segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJOrCuAS2sdu"
      },
      "source": [
        "2025/05/19 -- 05/20 -- 05/21 -- 05/22"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6sjlE1PtqaL",
        "outputId": "ced4a35a-d44d-421f-cf34-7c295b5ce8f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras_tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (from keras_tuner) (3.8.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras_tuner) (25.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from keras_tuner) (2.32.3)\n",
            "Collecting kt-legacy (from keras_tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras->keras_tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras->keras_tuner) (2.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras->keras_tuner) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras->keras_tuner) (0.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras->keras_tuner) (3.14.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras->keras_tuner) (0.16.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras->keras_tuner) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->keras_tuner) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->keras_tuner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->keras_tuner) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->keras_tuner) (2025.7.14)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras->keras_tuner) (4.14.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras_tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras_tuner) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras_tuner) (0.1.2)\n",
            "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: kt-legacy, keras_tuner\n",
            "Successfully installed keras_tuner-1.4.7 kt-legacy-1.0.5\n"
          ]
        }
      ],
      "source": [
        "!pip install keras_tuner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "iv4pwakFv5tc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import cv2\n",
        "import nibabel as nb\n",
        "from sklearn.model_selection import train_test_split,GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Conv2DTranspose, Dropout, concatenate, Input\n",
        "from tensorflow.keras.models import Model,load_model\n",
        "import keras_tuner as kt\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXf5rAMT2niV",
        "outputId": "4a1b70dc-158f-4f33-8708-044f00763124"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /kaggle/input/brats20-dataset-training-validation\n",
            "['BraTS2020_ValidationData', 'BraTS2020_TrainingData']\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "import os\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"awsaf49/brats20-dataset-training-validation\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)\n",
        "print(os.listdir(path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4w6PZgtN7h7T"
      },
      "outputs": [],
      "source": [
        "dir_path = \"BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData\"\n",
        "base_path = os.path.join(path,dir_path)\n",
        "slice_index = 75"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "umABZG5V7x5D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "facb8d26-d8f9-46ba-bd39-d5c53d770644"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping BraTS20_Training_355: No such file or no access: '/kaggle/input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_355/BraTS20_Training_355_seg.nii'\n"
          ]
        }
      ],
      "source": [
        "mobilities = ['t1','t2','flair','t1ce']\n",
        "X_data = []\n",
        "Y_data = []\n",
        "\n",
        "for subject_folder in os.listdir(base_path):\n",
        "    subject_path = os.path.join(base_path, subject_folder)\n",
        "    if not os.path.isdir(subject_path) or not subject_folder.startswith(\"BraTS20_Training_\"):\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        # Load all modalities once\n",
        "        vols = {}\n",
        "        for mod in mobilities:\n",
        "            file_path = os.path.join(subject_path, f\"{subject_folder}_{mod}.nii\")\n",
        "            vols[mod] = nb.load(file_path).get_fdata()\n",
        "\n",
        "        mask_path = os.path.join(subject_path, f\"{subject_folder}_seg.nii\")\n",
        "        seg = nb.load(mask_path).get_fdata()\n",
        "\n",
        "        # Loop through multiple slices\n",
        "        for slice_index in range(60, 91):  # 60 to 90\n",
        "            channels = []\n",
        "            skip = False\n",
        "\n",
        "            for mod in mobilities:\n",
        "                slice_ = vols[mod][:, :, slice_index]\n",
        "                resized = cv2.resize(slice_, (128, 128))\n",
        "                norm = (resized - np.min(resized)) / (np.max(resized) - np.min(resized) + 1e-8)\n",
        "                channels.append(norm)\n",
        "\n",
        "            x = np.stack(channels, axis=-1)\n",
        "\n",
        "            mask_slice = seg[:, :, slice_index]\n",
        "            if np.max(mask_slice) == 0:\n",
        "                continue  # skip slices with no tumor\n",
        "\n",
        "            mask_resized = cv2.resize(mask_slice, (128, 128), interpolation=cv2.INTER_NEAREST)\n",
        "            y = (mask_resized > 0).astype(np.float32)[..., np.newaxis]\n",
        "\n",
        "            X_data.append(x)\n",
        "            Y_data.append(y)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Skipping {subject_folder}: {e}\")\n",
        "\n",
        "X_data = np.array(X_data)\n",
        "Y_data = np.array(Y_data)\n",
        "print(\"Final shape:\", X_data.shape, Y_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q2sK3TFH8C2U"
      },
      "outputs": [],
      "source": [
        "print(X_data.shape)\n",
        "print(Y_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zF0dZILX-krt"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_data, Y_data, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Flby-5eqcEHk"
      },
      "source": [
        "# U-net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Plf0ckXcvUvI"
      },
      "outputs": [],
      "source": [
        "def unet_model(hp):\n",
        "    inputs = Input(shape=(128, 128, 4))\n",
        "\n",
        "    # Tune dropout\n",
        "    dropout_rate = hp.Float('dropout', min_value=0.2, max_value=0.5, step=0.1)\n",
        "\n",
        "    # Tune number of filters\n",
        "    f1 = hp.Choice('filters_layer1', values=[16, 32, 64])\n",
        "\n",
        "    # Encoder\n",
        "    c1 = Conv2D(f1, 3, activation='relu', padding='same')(inputs)\n",
        "    c1 = Dropout(dropout_rate)(c1)\n",
        "    c1 = Conv2D(f1, 3, activation='relu', padding='same')(c1)\n",
        "    p1 = MaxPooling2D()(c1)\n",
        "\n",
        "    f2 = f1 * 2\n",
        "    c2 = Conv2D(f2, 3, activation='relu', padding='same')(p1)\n",
        "    c2 = Dropout(dropout_rate)(c2)\n",
        "    c2 = Conv2D(f2, 3, activation='relu', padding='same')(c2)\n",
        "    p2 = MaxPooling2D()(c2)\n",
        "\n",
        "    f3 = f2 * 2\n",
        "    c3 = Conv2D(f3, 3, activation='relu', padding='same')(p2)\n",
        "    c3 = Dropout(dropout_rate)(c3)\n",
        "    c3 = Conv2D(f3, 3, activation='relu', padding='same')(c3)\n",
        "    p3 = MaxPooling2D()(c3)\n",
        "\n",
        "    # Bottleneck\n",
        "    f4 = f3 * 2\n",
        "    c4 = Conv2D(f4, 3, activation='relu', padding='same')(p3)\n",
        "    c4 = Dropout(dropout_rate)(c4)\n",
        "    c4 = Conv2D(f4, 3, activation='relu', padding='same')(c4)\n",
        "\n",
        "    # Decoder\n",
        "    u1 = Conv2DTranspose(f3, 2, strides=2, padding='same')(c4)\n",
        "    u1 = concatenate([u1, c3])\n",
        "    c5 = Conv2D(f3, 3, activation='relu', padding='same')(u1)\n",
        "    c5 = Conv2D(f3, 3, activation='relu', padding='same')(c5)\n",
        "\n",
        "    u2 = Conv2DTranspose(f2, 2, strides=2, padding='same')(c5)\n",
        "    u2 = concatenate([u2, c2])\n",
        "    c6 = Conv2D(f2, 3, activation='relu', padding='same')(u2)\n",
        "    c6 = Conv2D(f2, 3, activation='relu', padding='same')(c6)\n",
        "\n",
        "    u3 = Conv2DTranspose(f1, 2, strides=2, padding='same')(c6)\n",
        "    u3 = concatenate([u3, c1])\n",
        "    c7 = Conv2D(f1, 3, activation='relu', padding='same')(u3)\n",
        "    c7 = Conv2D(f1, 3, activation='relu', padding='same')(c7)\n",
        "\n",
        "    outputs = Conv2D(1, 1, activation='sigmoid')(c7)\n",
        "\n",
        "    model = Model(inputs=[inputs], outputs=[outputs])\n",
        "\n",
        "    # Tune learning rate\n",
        "    lr = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "    model.compile(optimizer=Adam(learning_rate=lr), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqmVXcPk7Tcw"
      },
      "source": [
        "--break point --"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1XITZFC_NEgV"
      },
      "outputs": [],
      "source": [
        "tuner = kt.RandomSearch(\n",
        "    unet_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=5,\n",
        "    executions_per_trial=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nJCxCqMUco9t"
      },
      "outputs": [],
      "source": [
        "tuner.search(X_train, y_train, epochs=5, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ivcVYFL2dGn5"
      },
      "outputs": [],
      "source": [
        "best_model = tuner.get_best_models(num_models=1)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a9hg0o-JeFxT"
      },
      "outputs": [],
      "source": [
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "best_learning_rate = best_hps.get('learning_rate')\n",
        "best_dropout = best_hps.get('dropout')\n",
        "# print(f\"Best dropout: {best_dropout}\")\n",
        "print(f\"Best learning rate: {best_learning_rate}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qPLHBVATeKKT"
      },
      "outputs": [],
      "source": [
        "def unet_final_model(learning_rate,dropout_rate):\n",
        "\n",
        "  input = Input((128,128,4))\n",
        "\n",
        "  #Encoder\n",
        "  c1 = Conv2D(16,(3,3),activation=\"relu\",padding=\"same\")(input)\n",
        "  c1 = Dropout(dropout_rate)(c1)\n",
        "  c1 = Conv2D(16,(3,3),activation=\"relu\",padding=\"same\")(c1)\n",
        "  p1 = MaxPooling2D((2,2))(c1)\n",
        "\n",
        "  c2 = Conv2D(32,(3,3),activation=\"relu\",padding= \"same\")(p1)\n",
        "  c2 = Dropout(dropout_rate)(c2)\n",
        "  c2 = Conv2D(32,(3,3),activation=\"relu\",padding=\"same\")(c2)\n",
        "  p2 = MaxPooling2D((2,2))(c2)\n",
        "\n",
        "  c3 = Conv2D(64,(3,3),activation=\"relu\",padding=\"same\")(p2)\n",
        "  c3 = Dropout(dropout_rate)(c3)\n",
        "  c3 = Conv2D(64,(3,3),activation=\"relu\",padding=\"same\")(c3)\n",
        "  p3 = MaxPooling2D((2,2))(c3)\n",
        "\n",
        "  c4 = Conv2D(128,(3,3),activation=\"relu\",padding=\"same\")(p3)\n",
        "  c4 = Dropout(dropout_rate)(c4)\n",
        "  c4 = Conv2D(128,(3,3),activation=\"relu\",padding=\"same\")(c4)\n",
        "  p4 = MaxPooling2D((2,2))(c4)\n",
        "\n",
        "  #Bottlefask\n",
        "  c5 = Conv2D(256,(3,3),activation=\"relu\",padding=\"same\")(p4)\n",
        "  c5 = Dropout(dropout_rate)(c5)\n",
        "  c5 = Conv2D(256,(3,3),activation=\"relu\",padding=\"same\")(c5)\n",
        "\n",
        "  #Decoder\n",
        "  u1 = Conv2DTranspose(128,(2,2),strides=(2,2),padding=\"same\")(c5)\n",
        "  u1 = concatenate([u1,c4])\n",
        "  c6 = Conv2D(128,(3,3),activation=\"relu\",padding=\"same\")(u1)\n",
        "\n",
        "  u2 = Conv2DTranspose(64,(2,2),strides=(2,2),padding=\"same\")(c6)\n",
        "  u2 = concatenate([u2,c3])\n",
        "  c7 = Conv2D(64,(3,3),activation=\"relu\",padding=\"same\")(u2)\n",
        "\n",
        "  u3 = Conv2DTranspose(32,(2,2),strides=(2,2),padding=\"same\")(c7)\n",
        "  u3 = concatenate([u3,c2])\n",
        "  c8 = Conv2D(32,(3,3),activation=\"relu\",padding=\"same\")(u3)\n",
        "\n",
        "  u4 = Conv2DTranspose(16,(2,2),strides=(2,2),padding=\"same\")(c8)\n",
        "  u4 = concatenate([u4,c1])\n",
        "  c9 = Conv2D(16,(3,3),activation=\"relu\",padding=\"same\")(u4)\n",
        "\n",
        "  output = Conv2D(1,(1,1),activation=\"sigmoid\")(c9)\n",
        "\n",
        "  model = Model(inputs=input,outputs=output )\n",
        "  model.compile(optimizer=Adam(learning_rate=learning_rate),loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OdWKmNOYnW04"
      },
      "outputs": [],
      "source": [
        "model = unet_final_model(\n",
        "  learning_rate = best_learning_rate,\n",
        "  dropout_rate = best_dropout\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RHAyFH9Fn3pP"
      },
      "outputs": [],
      "source": [
        "fitting = model.fit(X_train,y_train,validation_split=0.2,batch_size=8,epochs=20)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = 'model.h5'"
      ],
      "metadata": {
        "id": "BeLMsMQjUhgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.exists(model_path):\n",
        "    model = load_model(model_path, compile=False)\n",
        "    print(\"✅ Trained model loaded successfully!\")\n",
        "else:\n",
        "    raise FileNotFoundError(\"❌ Saved model 'model.h5' not found. Please train and save the model first.\")"
      ],
      "metadata": {
        "id": "6dWi0HhEUsHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gwpQA6bOreeE"
      },
      "outputs": [],
      "source": [
        "# Predict on validation/test data\n",
        "# For example, use the first 10 samples\n",
        "n = 15\n",
        "preds = model.predict(X_data[:n])\n",
        "\n",
        "# Threshold predictions to make them binary (0 or 1)\n",
        "preds_thresholded = (preds > 0.5).astype(np.uint8)\n",
        "\n",
        "# Plot each sample\n",
        "for i in range(n):\n",
        "    fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n",
        "\n",
        "    # Input image (let’s take the first channel for display)\n",
        "    axs[0].imshow(X_data[i][:, :, 0], cmap='gray')\n",
        "    axs[0].set_title(\"Input (FLAIR)\")\n",
        "    axs[0].axis('off')\n",
        "\n",
        "    # Ground Truth\n",
        "    axs[1].imshow(Y_data[i][:, :, 0], cmap='Reds')\n",
        "    axs[1].set_title(\"Ground Truth Mask\")\n",
        "    axs[1].axis('off')\n",
        "\n",
        "    # Prediction\n",
        "    axs[2].imshow(preds_thresholded[i][:, :, 0], cmap='Reds')\n",
        "    axs[2].set_title(\"Predicted Mask\")\n",
        "    axs[2].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"segmentation_result.png\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "paMIoImxpSJt"
      },
      "outputs": [],
      "source": [
        "if 'model' in locals() and isinstance(model, tf.keras.Model):\n",
        "    best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "    best_learning_rate = best_hps.get('learning_rate')\n",
        "\n",
        "    model.compile(optimizer=Adam(learning_rate=best_learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "loss, acc = model.evaluate(X_test, y_test)\n",
        "print(f\"🎯 Test Accuracy: {acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "HRlCEOwSRq8o"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(fitting.history['accuracy'], label='Train Accuracy') # Updated to use 'accuracy'\n",
        "plt.plot(fitting.history['val_accuracy'], label='Val Accuracy') # Updated to use 'val_accuracy'\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\") # Updated label\n",
        "plt.title(\"Accuracy Over Epochs\") # Updated title\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.savefig(\"accuracy_graph.png\")  # Updated filename\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fmtv00HWhBf2"
      },
      "outputs": [],
      "source": [
        "def dice_coefficient(y_true, y_pred, smooth=1e-6):\n",
        "    y_true_f = tf.keras.backend.flatten(y_true)\n",
        "    y_pred_f = tf.keras.backend.flatten(y_pred)\n",
        "    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + smooth)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JKNzL6X4hUUV"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coefficient])\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88011bd7"
      },
      "source": [
        "def iou(y_true, y_pred, smooth=1e-6):\n",
        "    y_true_f = tf.keras.backend.flatten(y_true)\n",
        "    y_pred_f = tf.keras.backend.flatten(y_pred)\n",
        "    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n",
        "    union = tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) - intersection\n",
        "    return (intersection + smooth) / (union + smooth)\n",
        "\n",
        "# Evaluate the model on the test data using the new metrics\n",
        "loss, dice, iou_score = model.evaluate(X_test, y_test)\n",
        "\n",
        "print(f\"🎯 Test Loss: {loss:.4f}\")\n",
        "print(f\"🎯 Test Dice Coefficient: {dice:.4f}\")\n",
        "print(f\"🎯 Test IoU: {iou_score:.4f}\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPyQQAbHd4bkrHhiyxkjPIH",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}